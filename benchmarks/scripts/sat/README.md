# Scripts for benchmarking MLTL sat via C2PO

To build an apptainer run:

    apptainer build sat.sif sat.def

This is an immutable executable that is suitable for running on a cluster. 
The slurm scripts generated by `generate_slurm.py` will create a script for each benchmark.
We assume that there is a directory with the following structure:
```
random/
    random-10/
    random-100/
    random-1000/
    random-10000/
```
for each benchmark to be run over.

Use `cactus.py` to generate cactus plots. 

Use `report.py` to validate that test results for any failures and disagreements.

Use `vp.py` to generate a virtual best for a set of benchmarks. Use the `-data` flag to also output some useful data. 

The benchmarks use 1200s for timeout (same as SMTCOMP 2022) and 16GB for memout.
